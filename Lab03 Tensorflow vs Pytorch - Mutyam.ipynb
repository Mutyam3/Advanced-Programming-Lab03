{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNnlNFy9aoHVpxqu7SXp+U7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Lab 03: TensorFlow vs. PyTorch\n","\n","• Build and train the same small neural network model using both TensorFlow and PyTorch.\n","\n","• Measure and compare training time and performance.\n","\n","• Convert the trained models into lightweight formats suitable for embedded deployment: Tensor-\n","Flow Lite and ONNX."],"metadata":{"id":"JEyqtS1lBQrd"}},{"cell_type":"markdown","source":["## Tensorflow Implementation"],"metadata":{"id":"abqh1hCb81PN"}},{"cell_type":"code","execution_count":16,"metadata":{"id":"TJVqGvALPjXM","executionInfo":{"status":"ok","timestamp":1751106680573,"user_tz":-120,"elapsed":41,"user":{"displayName":"Bhargav Reddy Mutyam","userId":"12262767635714446426"}}},"outputs":[],"source":["import tensorflow as tf\n","# Use the MNIST dataset of handwritten digits (28x28 grayscale images, 10 classes).\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","import time"]},{"cell_type":"code","source":["\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = x_train / 255   # Fill in normalization factor\n","x_test = x_test / 255     # Fill in normalization factor\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)"],"metadata":{"id":"3hDjFvIpQytI","executionInfo":{"status":"ok","timestamp":1751106682440,"user_tz":-120,"elapsed":414,"user":{"displayName":"Bhargav Reddy Mutyam","userId":"12262767635714446426"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Architecture\n","# • Flatten input (784 features)\n","# • Dense layer with 64 ReLU units\n","# • Output layer with 10 units (softmax for TensorFlow)"],"metadata":{"id":"ipLnFtf-ShlP","executionInfo":{"status":"ok","timestamp":1751106683921,"user_tz":-120,"elapsed":3,"user":{"displayName":"Bhargav Reddy Mutyam","userId":"12262767635714446426"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Input(shape=(28, 28)),              # Input shape: 28x28 pixels\n","    tf.keras.layers.Flatten(),                          # Flatten to 784 features\n","    tf.keras.layers.Dense(64, activation='relu'),       # Hidden layer with 64 neurons\n","    tf.keras.layers.Dense(10, activation='softmax')     # Output layer: 10 classes (digits 0–9)\n","])\n"],"metadata":{"id":"5XDmpgtrRWo7","executionInfo":{"status":"ok","timestamp":1751106685892,"user_tz":-120,"elapsed":25,"user":{"displayName":"Bhargav Reddy Mutyam","userId":"12262767635714446426"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',       # Fill name of loss function (# Because labels are one-hot encoded)\n","              metrics=['accuracy'])\n","\n","start = time.time()\n","model.fit(x_train, y_train, epochs=5)\n","end = time.time()\n","print(f\"TF Training time: {end-start:.2f} seconds\")       # Output training time\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xi2ZVkYCScxu","executionInfo":{"status":"ok","timestamp":1751106717756,"user_tz":-120,"elapsed":30015,"user":{"displayName":"Bhargav Reddy Mutyam","userId":"12262767635714446426"}},"outputId":"ea1a878b-0357-4be6-e8af-0df907512036"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8605 - loss: 0.5048\n","Epoch 2/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1490\n","Epoch 3/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.1072\n","Epoch 4/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9771 - loss: 0.0787\n","Epoch 5/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9806 - loss: 0.0635\n","TF Training time: 29.95 seconds\n"]}]},{"cell_type":"markdown","source":[" Tensorflow - Test accuracy and Inference time using TensorFlow’s model.evaluate()"],"metadata":{"id":"ixpJKIknATyw"}},{"cell_type":"code","source":["# Measure inference time and get evaluation metrics\n","start_inference = time.time()\n","\n","# model.evaluate runs inference on the test set and returns [loss, accuracy]\n","test_loss, test_accuracy = model.evaluate(x_test, y_test)\n","\n","end_inference = time.time()\n","inference_time = end_inference - start_inference\n","\n","# Print results\n","print(f\"Loss: {test_loss}\")\n","print(f\"Test Accuracy: {test_accuracy}\")\n","print(f\"Test Accuracy in Percentage: {test_accuracy * 100:.2f}%\")\n","print(f\"Inference Time on Test Set: {inference_time:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZnmPPVMWflkC","executionInfo":{"status":"ok","timestamp":1751106915944,"user_tz":-120,"elapsed":1077,"user":{"displayName":"Bhargav Reddy Mutyam","userId":"12262767635714446426"}},"outputId":"8fcb5ea3-eb7b-47bd-9a5d-0328ff3b73d0"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.1015\n","Loss: 0.08883529156446457\n","Test Accuracy: 0.9722999930381775\n","Test Accuracy in Percentage: 97.23%\n","Inference Time on Test Set: 1.07 seconds\n"]}]},{"cell_type":"markdown","source":["Convert the trained model to TensorFlow Lite using TFLiteConverter."],"metadata":{"id":"Z4pRF0Nq_8J5"}},{"cell_type":"code","source":["converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","with open('model.tflite', 'wb') as f:\n","    f.write(tflite_model)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LasW_2bsgm38","executionInfo":{"status":"ok","timestamp":1751106826788,"user_tz":-120,"elapsed":288,"user":{"displayName":"Bhargav Reddy Mutyam","userId":"12262767635714446426"}},"outputId":"925e901c-56a6-4432-cea8-7880362e927e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved artifact at '/tmp/tmpnvx7udma'. The following endpoints are available:\n","\n","* Endpoint 'serve'\n","  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='keras_tensor_4')\n","Output Type:\n","  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n","Captures:\n","  133417729333136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  133417729333712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  133417729333904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  133417729335056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"]}]},{"cell_type":"markdown","source":["## Pytorch Implementation"],"metadata":{"id":"jXhzY84JnYQd"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n","train_loader = DataLoader(datasets.MNIST(root='./data', train=True, transform=transform, download=True), batch_size=32)\n","test_loader = DataLoader(datasets.MNIST(root='./data', train=False, transform=transform, download=True), batch_size=1000)\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(784, 64)    # Fill correct input and output size\n","        self.fc2 = nn.Linear(64, 10)    # Fill correct input and output size\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))    # Fill correct layer\n","        return self.fc2(x)    # Fill correct layer\n","\n","model = Net()\n","optimizer = optim.Adam(model.parameters())\n","loss_fn = nn.CrossEntropyLoss()\n","\n","start = time.time()\n","\n","for epoch in range(5):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    for x, y in train_loader:\n","        optimizer.zero_grad()\n","        pred = model(x)\n","        loss = loss_fn(pred, y)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = torch.max(pred.data, 1)\n","        total += y.size(0)\n","        correct += (predicted == y).sum().item()\n","\n","    epoch_loss = running_loss / len(train_loader)\n","    epoch_acc = 100 * correct / total\n","    print(f\"Epoch {epoch+1}:  Accuracy = {epoch_acc} - Loss = {epoch_loss}\")\n","\n","end = time.time()\n","print(f\"PyTorch Training time: {end - start:.2f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BajF0rmvxK_J","executionInfo":{"status":"ok","timestamp":1751108233849,"user_tz":-120,"elapsed":48038,"user":{"displayName":"Bhargav Reddy Mutyam","userId":"12262767635714446426"}},"outputId":"366bdf8f-111c-43a1-b002-ec6cc8e3224c"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1:  Accuracy = 90.68333333333334 - Loss = 0.34226688976734876\n","Epoch 2:  Accuracy = 95.075 - Loss = 0.1697697012681514\n","Epoch 3:  Accuracy = 96.36333333333333 - Loss = 0.1245271462171028\n","Epoch 4:  Accuracy = 97.15166666666667 - Loss = 0.097628630991932\n","Epoch 5:  Accuracy = 97.68666666666667 - Loss = 0.07935793280173094\n","PyTorch Training time: 47.98 seconds\n"]}]},{"cell_type":"markdown","source":["Inference and Evaluation using PyTorch’s model.eval() + torch.no_grad()."],"metadata":{"id":"AqvUZyvEDF_R"}},{"cell_type":"code","source":["#Inference and Evaluation using PyTorch’s model.eval() + torch.no_grad().\n","model.eval()\n","correct = 0\n","\n","start_time = time.time()\n","\n","with torch.no_grad():\n","    for x, y in test_loader:\n","        output = model(x)\n","        pred = output.argmax(1)\n","        correct += (pred == y).sum().item()\n","\n","end_time = time.time()\n","\n","inference_time = end_time - start_time\n","\n","print(f\"Test accuracy: {correct / len(test_loader.dataset):.4f}\")\n","print(f\"Inference Time: {inference_time:.4f} seconds\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I4u-kq-62AHx","executionInfo":{"status":"ok","timestamp":1751106260617,"user_tz":-120,"elapsed":1033,"user":{"displayName":"Bhargav Reddy Mutyam","userId":"12262767635714446426"}},"outputId":"a6a5f89b-6d85-4a80-9d59-3d5c6ed98d8a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy: 0.9661\n","Inference Time: 1.0223 seconds\n"]}]},{"cell_type":"markdown","source":["convert the trained model into lightweight formats - using ONNX\n","1. Export the model to ONNX format.\n","2. Use dummy input with correct shape (e.g. torch.randn(1, 784)).\n","3. Save as model.onnx."],"metadata":{"id":"EqDR7ghhplTL"}},{"cell_type":"code","source":["# Install ONNX\n","!pip install onnx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fg8B05z4zBoi","executionInfo":{"status":"ok","timestamp":1751106268190,"user_tz":-120,"elapsed":4201,"user":{"displayName":"Bhargav Reddy Mutyam","userId":"12262767635714446426"}},"outputId":"38dbd7d4-d837-4258-edaa-1b9cdaa263e6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.18.0)\n","Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n","Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n","Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.0)\n"]}]},{"cell_type":"code","source":["dummy_input = torch.randn(1, 784)\n","torch.onnx.export(model, dummy_input, \"model.onnx\",\n","                  input_names=[\"input\"], output_names=[\"output\"])\n","print('Successfully saved the model as model.onnx')"],"metadata":{"id":"8aM4mLT5zGmB","executionInfo":{"status":"ok","timestamp":1751106377551,"user_tz":-120,"elapsed":59,"user":{"displayName":"Bhargav Reddy Mutyam","userId":"12262767635714446426"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b55bb482-0688-43ab-f1d6-69ed42a9ede0"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully saved the model as model.onnx\n"]}]},{"cell_type":"markdown","source":["# TensorFlow custom training loop using tf.GradientTape"],"metadata":{"id":"j_Rr7mHb-xxp"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","import time\n","\n","# Load and preprocess data\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = x_train / 255   # Fill in normalization factor\n","x_test = x_test / 255   # Fill in normalization factor\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","# Prepare datasets\n","batch_size = 32         # Fill same batch size as in first TF example\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size)\n","test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n","\n","# Define model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Input(shape=(28, 28)),    # Fill size\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(64, activation='relu'),    # Fill number of neurons and activation\n","    tf.keras.layers.Dense(10, activation='softmax')     # Fill number of neurons and activation\n","])\n","\n","# Define loss, optimizer, and metrics\n","loss_fn = tf.keras.losses.CategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.Adam()\n","train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n","test_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n","\n","# Training loop\n","epochs = 5\n","start = time.time()\n","for epoch in range(epochs):\n","    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n","    for step, (x_batch, y_batch) in enumerate(train_dataset):\n","        with tf.GradientTape() as tape:\n","            logits = model(x_batch, training=True)\n","            loss = loss_fn(y_batch, logits)\n","        grads = tape.gradient(loss, model.trainable_variables)\n","        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","        train_acc_metric.update_state(y_batch, logits)\n","\n","        if step % 100 == 0:\n","            print(f\"Step {step}, Loss: {loss.numpy():.4f}, Accuracy: {train_acc_metric.result().numpy():.4f}\")\n","\n","    print(f\"Training Accuracy for epoch {epoch+1}: {train_acc_metric.result().numpy():.4f}\")\n","    train_acc_metric.reset_state()\n","end = time.time()\n","print(f\"\\nTF Training time: {end - start:.2f} seconds\")\n","\n","# Evaluation loop\n","for x_batch, y_batch in test_dataset:\n","    test_logits = model(x_batch, training=False)\n","    test_acc_metric.update_state(y_batch, test_logits)\n","\n","print(f\"Test Accuracy: {test_acc_metric.result().numpy():.4f}\")\n"],"metadata":{"id":"KH-sDlHq_Gdw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751104976194,"user_tz":-120,"elapsed":362151,"user":{"displayName":"Bhargav Reddy Mutyam","userId":"12262767635714446426"}},"outputId":"5d286451-de49-4438-8687-2e6aa2e86097"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1/5\n","Step 0, Loss: 2.3947, Accuracy: 0.0625\n","Step 100, Loss: 0.5532, Accuracy: 0.7119\n","Step 200, Loss: 0.4767, Accuracy: 0.7920\n","Step 300, Loss: 0.2381, Accuracy: 0.8253\n","Step 400, Loss: 0.3819, Accuracy: 0.8461\n","Step 500, Loss: 0.5366, Accuracy: 0.8595\n","Step 600, Loss: 0.2839, Accuracy: 0.8697\n","Step 700, Loss: 0.3174, Accuracy: 0.8758\n","Step 800, Loss: 0.3370, Accuracy: 0.8817\n","Step 900, Loss: 0.3957, Accuracy: 0.8863\n","Step 1000, Loss: 0.2489, Accuracy: 0.8911\n","Step 1100, Loss: 0.1612, Accuracy: 0.8954\n","Step 1200, Loss: 0.2258, Accuracy: 0.8987\n","Step 1300, Loss: 0.0997, Accuracy: 0.9016\n","Step 1400, Loss: 0.1841, Accuracy: 0.9037\n","Step 1500, Loss: 0.0540, Accuracy: 0.9065\n","Step 1600, Loss: 0.4140, Accuracy: 0.9091\n","Step 1700, Loss: 0.2169, Accuracy: 0.9111\n","Step 1800, Loss: 0.1698, Accuracy: 0.9127\n","Training Accuracy for epoch 1: 0.9143\n","\n","Epoch 2/5\n","Step 0, Loss: 0.0627, Accuracy: 0.9688\n","Step 100, Loss: 0.1259, Accuracy: 0.9446\n","Step 200, Loss: 0.3803, Accuracy: 0.9510\n","Step 300, Loss: 0.1471, Accuracy: 0.9523\n","Step 400, Loss: 0.1141, Accuracy: 0.9534\n","Step 500, Loss: 0.1101, Accuracy: 0.9536\n","Step 600, Loss: 0.5549, Accuracy: 0.9535\n","Step 700, Loss: 0.2088, Accuracy: 0.9536\n","Step 800, Loss: 0.1213, Accuracy: 0.9531\n","Step 900, Loss: 0.0693, Accuracy: 0.9538\n","Step 1000, Loss: 0.0622, Accuracy: 0.9541\n","Step 1100, Loss: 0.2103, Accuracy: 0.9542\n","Step 1200, Loss: 0.3696, Accuracy: 0.9545\n","Step 1300, Loss: 0.1428, Accuracy: 0.9544\n","Step 1400, Loss: 0.1683, Accuracy: 0.9545\n","Step 1500, Loss: 0.0655, Accuracy: 0.9548\n","Step 1600, Loss: 0.0155, Accuracy: 0.9555\n","Step 1700, Loss: 0.2858, Accuracy: 0.9558\n","Step 1800, Loss: 0.0892, Accuracy: 0.9564\n","Training Accuracy for epoch 2: 0.9565\n","\n","Epoch 3/5\n","Step 0, Loss: 0.0169, Accuracy: 1.0000\n","Step 100, Loss: 0.1668, Accuracy: 0.9675\n","Step 200, Loss: 0.1872, Accuracy: 0.9660\n","Step 300, Loss: 0.0470, Accuracy: 0.9662\n","Step 400, Loss: 0.1119, Accuracy: 0.9650\n","Step 500, Loss: 0.1181, Accuracy: 0.9641\n","Step 600, Loss: 0.1048, Accuracy: 0.9637\n","Step 700, Loss: 0.0515, Accuracy: 0.9634\n","Step 800, Loss: 0.0222, Accuracy: 0.9646\n","Step 900, Loss: 0.0702, Accuracy: 0.9649\n","Step 1000, Loss: 0.2977, Accuracy: 0.9652\n","Step 1100, Loss: 0.2373, Accuracy: 0.9656\n","Step 1200, Loss: 0.1344, Accuracy: 0.9658\n","Step 1300, Loss: 0.1300, Accuracy: 0.9656\n","Step 1400, Loss: 0.4613, Accuracy: 0.9657\n","Step 1500, Loss: 0.0536, Accuracy: 0.9659\n","Step 1600, Loss: 0.0350, Accuracy: 0.9666\n","Step 1700, Loss: 0.1690, Accuracy: 0.9670\n","Step 1800, Loss: 0.0939, Accuracy: 0.9673\n","Training Accuracy for epoch 3: 0.9675\n","\n","Epoch 4/5\n","Step 0, Loss: 0.0342, Accuracy: 1.0000\n","Step 100, Loss: 0.0758, Accuracy: 0.9725\n","Step 200, Loss: 0.2453, Accuracy: 0.9733\n","Step 300, Loss: 0.1809, Accuracy: 0.9723\n","Step 400, Loss: 0.0042, Accuracy: 0.9730\n","Step 500, Loss: 0.0369, Accuracy: 0.9732\n","Step 600, Loss: 0.1815, Accuracy: 0.9733\n","Step 700, Loss: 0.1826, Accuracy: 0.9728\n","Step 800, Loss: 0.0285, Accuracy: 0.9727\n","Step 900, Loss: 0.0409, Accuracy: 0.9731\n","Step 1000, Loss: 0.0445, Accuracy: 0.9736\n","Step 1100, Loss: 0.0146, Accuracy: 0.9739\n","Step 1200, Loss: 0.1041, Accuracy: 0.9737\n","Step 1300, Loss: 0.1136, Accuracy: 0.9733\n","Step 1400, Loss: 0.0091, Accuracy: 0.9733\n","Step 1500, Loss: 0.0191, Accuracy: 0.9734\n","Step 1600, Loss: 0.0152, Accuracy: 0.9737\n","Step 1700, Loss: 0.0165, Accuracy: 0.9739\n","Step 1800, Loss: 0.2033, Accuracy: 0.9739\n","Training Accuracy for epoch 4: 0.9741\n","\n","Epoch 5/5\n","Step 0, Loss: 0.0135, Accuracy: 1.0000\n","Step 100, Loss: 0.1032, Accuracy: 0.9793\n","Step 200, Loss: 0.0679, Accuracy: 0.9796\n","Step 300, Loss: 0.1667, Accuracy: 0.9800\n","Step 400, Loss: 0.0283, Accuracy: 0.9797\n","Step 500, Loss: 0.0452, Accuracy: 0.9790\n","Step 600, Loss: 0.0741, Accuracy: 0.9786\n","Step 700, Loss: 0.0521, Accuracy: 0.9784\n","Step 800, Loss: 0.1361, Accuracy: 0.9788\n","Step 900, Loss: 0.3172, Accuracy: 0.9788\n","Step 1000, Loss: 0.1180, Accuracy: 0.9792\n","Step 1100, Loss: 0.0026, Accuracy: 0.9792\n","Step 1200, Loss: 0.0319, Accuracy: 0.9788\n","Step 1300, Loss: 0.0485, Accuracy: 0.9788\n","Step 1400, Loss: 0.2224, Accuracy: 0.9785\n","Step 1500, Loss: 0.1673, Accuracy: 0.9783\n","Step 1600, Loss: 0.0208, Accuracy: 0.9783\n","Step 1700, Loss: 0.0361, Accuracy: 0.9783\n","Step 1800, Loss: 0.0287, Accuracy: 0.9784\n","Training Accuracy for epoch 5: 0.9785\n","\n","TF Training time: 357.70 seconds\n","Test Accuracy: 0.9700\n"]}]},{"cell_type":"markdown","source":["## Performance Optimization with Graph Execution using @tf.function"],"metadata":{"id":"OQqSrMDU-AlL"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","import time\n","\n","# Load and preprocess data\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = x_train / 255   # Fill in normalization factor\n","x_test = x_test / 255   # Fill in normalization factor\n","y_train = to_categorical(y_train, num_classes=10)\n","y_test = to_categorical(y_test, num_classes=10)\n","\n","# Prepare datasets\n","batch_size = 32\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size)\n","test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n","\n","# Define model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Input(shape=(28, 28)),    # Fill size\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(64, activation='relu'),    # Fill number of neurons and activation\n","    tf.keras.layers.Dense(10, activation='softmax')     # Fill number of neurons and activation\n","])\n","\n","# Define loss, optimizer, and metrics\n","loss_fn = tf.keras.losses.CategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.Adam()\n","train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n","test_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n","\n","@tf.function  # compile the function into a graph\n","def train_step(x_batch, y_batch):\n","    with tf.GradientTape() as tape:\n","        logits = model(x_batch, training=True)\n","        loss = loss_fn(y_batch, logits)\n","    grads = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","    train_acc_metric.update_state(y_batch, logits)\n","    return loss\n","\n","# Training loop\n","epochs = 5\n","start = time.time()\n","for epoch in range(epochs):\n","    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n","    for step, (x_batch, y_batch) in enumerate(train_dataset):\n","        loss = train_step(x_batch, y_batch)\n","\n","        if step % 100 == 0:\n","            print(f\"Step {step}, Loss: {loss.numpy():.4f}, Accuracy: {train_acc_metric.result().numpy():.4f}\")\n","\n","    print(f\"Training Accuracy for epoch {epoch+1}: {train_acc_metric.result().numpy():.4f}\")\n","    train_acc_metric.reset_state()\n","end = time.time()\n","print(f\"\\nTF Training time: {end - start:.2f} seconds\")\n","\n","# Evaluation loop\n","for x_batch, y_batch in test_dataset:\n","    test_logits = model(x_batch, training=False)\n","    test_acc_metric.update_state(y_batch, test_logits)\n","\n","print(f\"Test Accuracy: {test_acc_metric.result().numpy():.4f}\")\n"],"metadata":{"id":"Jmu_hciK_qle","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751105087542,"user_tz":-120,"elapsed":27448,"user":{"displayName":"Bhargav Reddy Mutyam","userId":"12262767635714446426"}},"outputId":"cb9ee2a1-48b6-444c-9336-9a50ba684398"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1/5\n","Step 0, Loss: 2.4904, Accuracy: 0.0625\n","Step 100, Loss: 0.6078, Accuracy: 0.7101\n","Step 200, Loss: 0.4359, Accuracy: 0.7886\n","Step 300, Loss: 0.2628, Accuracy: 0.8275\n","Step 400, Loss: 0.4302, Accuracy: 0.8499\n","Step 500, Loss: 0.3495, Accuracy: 0.8623\n","Step 600, Loss: 0.0857, Accuracy: 0.8720\n","Step 700, Loss: 0.4313, Accuracy: 0.8786\n","Step 800, Loss: 0.6529, Accuracy: 0.8849\n","Step 900, Loss: 0.0978, Accuracy: 0.8894\n","Step 1000, Loss: 0.2522, Accuracy: 0.8937\n","Step 1100, Loss: 0.1169, Accuracy: 0.8974\n","Step 1200, Loss: 0.1607, Accuracy: 0.8992\n","Step 1300, Loss: 0.2570, Accuracy: 0.9021\n","Step 1400, Loss: 0.3937, Accuracy: 0.9047\n","Step 1500, Loss: 0.3342, Accuracy: 0.9073\n","Step 1600, Loss: 0.0966, Accuracy: 0.9095\n","Step 1700, Loss: 0.1676, Accuracy: 0.9117\n","Step 1800, Loss: 0.1464, Accuracy: 0.9142\n","Training Accuracy for epoch 1: 0.9156\n","\n","Epoch 2/5\n","Step 0, Loss: 0.2268, Accuracy: 0.9062\n","Step 100, Loss: 0.1442, Accuracy: 0.9533\n","Step 200, Loss: 0.3749, Accuracy: 0.9498\n","Step 300, Loss: 0.0738, Accuracy: 0.9519\n","Step 400, Loss: 0.1994, Accuracy: 0.9522\n","Step 500, Loss: 0.0831, Accuracy: 0.9531\n","Step 600, Loss: 0.1797, Accuracy: 0.9529\n","Step 700, Loss: 0.0712, Accuracy: 0.9540\n","Step 800, Loss: 0.0552, Accuracy: 0.9541\n","Step 900, Loss: 0.0736, Accuracy: 0.9543\n","Step 1000, Loss: 0.2134, Accuracy: 0.9546\n","Step 1100, Loss: 0.0793, Accuracy: 0.9548\n","Step 1200, Loss: 0.0497, Accuracy: 0.9547\n","Step 1300, Loss: 0.2664, Accuracy: 0.9547\n","Step 1400, Loss: 0.0617, Accuracy: 0.9550\n","Step 1500, Loss: 0.0260, Accuracy: 0.9555\n","Step 1600, Loss: 0.0217, Accuracy: 0.9561\n","Step 1700, Loss: 0.1803, Accuracy: 0.9565\n","Step 1800, Loss: 0.0630, Accuracy: 0.9570\n","Training Accuracy for epoch 2: 0.9573\n","\n","Epoch 3/5\n","Step 0, Loss: 0.1941, Accuracy: 0.9688\n","Step 100, Loss: 0.1469, Accuracy: 0.9709\n","Step 200, Loss: 0.0909, Accuracy: 0.9684\n","Step 300, Loss: 0.2550, Accuracy: 0.9674\n","Step 400, Loss: 0.0974, Accuracy: 0.9688\n","Step 500, Loss: 0.3590, Accuracy: 0.9692\n","Step 600, Loss: 0.0318, Accuracy: 0.9673\n","Step 700, Loss: 0.1094, Accuracy: 0.9672\n","Step 800, Loss: 0.0796, Accuracy: 0.9679\n","Step 900, Loss: 0.0746, Accuracy: 0.9684\n","Step 1000, Loss: 0.2393, Accuracy: 0.9681\n","Step 1100, Loss: 0.0501, Accuracy: 0.9683\n","Step 1200, Loss: 0.3608, Accuracy: 0.9684\n","Step 1300, Loss: 0.0538, Accuracy: 0.9687\n","Step 1400, Loss: 0.0209, Accuracy: 0.9687\n","Step 1500, Loss: 0.2056, Accuracy: 0.9687\n","Step 1600, Loss: 0.2836, Accuracy: 0.9689\n","Step 1700, Loss: 0.0328, Accuracy: 0.9690\n","Step 1800, Loss: 0.0727, Accuracy: 0.9691\n","Training Accuracy for epoch 3: 0.9693\n","\n","Epoch 4/5\n","Step 0, Loss: 0.0492, Accuracy: 0.9688\n","Step 100, Loss: 0.0693, Accuracy: 0.9787\n","Step 200, Loss: 0.1641, Accuracy: 0.9765\n","Step 300, Loss: 0.1577, Accuracy: 0.9761\n","Step 400, Loss: 0.0533, Accuracy: 0.9755\n","Step 500, Loss: 0.1774, Accuracy: 0.9755\n","Step 600, Loss: 0.0760, Accuracy: 0.9757\n","Step 700, Loss: 0.2282, Accuracy: 0.9749\n","Step 800, Loss: 0.0171, Accuracy: 0.9752\n","Step 900, Loss: 0.0198, Accuracy: 0.9747\n","Step 1000, Loss: 0.3117, Accuracy: 0.9747\n","Step 1100, Loss: 0.0548, Accuracy: 0.9741\n","Step 1200, Loss: 0.0832, Accuracy: 0.9742\n","Step 1300, Loss: 0.0296, Accuracy: 0.9744\n","Step 1400, Loss: 0.0093, Accuracy: 0.9744\n","Step 1500, Loss: 0.0394, Accuracy: 0.9743\n","Step 1600, Loss: 0.0414, Accuracy: 0.9744\n","Step 1700, Loss: 0.0497, Accuracy: 0.9750\n","Step 1800, Loss: 0.0480, Accuracy: 0.9748\n","Training Accuracy for epoch 4: 0.9747\n","\n","Epoch 5/5\n","Step 0, Loss: 0.1639, Accuracy: 0.9375\n","Step 100, Loss: 0.0346, Accuracy: 0.9796\n","Step 200, Loss: 0.0290, Accuracy: 0.9771\n","Step 300, Loss: 0.0373, Accuracy: 0.9784\n","Step 400, Loss: 0.0051, Accuracy: 0.9785\n","Step 500, Loss: 0.0108, Accuracy: 0.9787\n","Step 600, Loss: 0.0073, Accuracy: 0.9790\n","Step 700, Loss: 0.0153, Accuracy: 0.9792\n","Step 800, Loss: 0.0084, Accuracy: 0.9795\n","Step 900, Loss: 0.0262, Accuracy: 0.9794\n","Step 1000, Loss: 0.0100, Accuracy: 0.9794\n","Step 1100, Loss: 0.2908, Accuracy: 0.9793\n","Step 1200, Loss: 0.0631, Accuracy: 0.9792\n","Step 1300, Loss: 0.1137, Accuracy: 0.9793\n","Step 1400, Loss: 0.0196, Accuracy: 0.9793\n","Step 1500, Loss: 0.0461, Accuracy: 0.9790\n","Step 1600, Loss: 0.0533, Accuracy: 0.9792\n","Step 1700, Loss: 0.0170, Accuracy: 0.9794\n","Step 1800, Loss: 0.0894, Accuracy: 0.9794\n","Training Accuracy for epoch 5: 0.9796\n","\n","TF Training time: 23.94 seconds\n","Test Accuracy: 0.9733\n"]}]}]}